{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7b0ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "SR = 16_000\n",
    "\n",
    "\n",
    "def adisplay(audio, rate=SR):\n",
    "    display(Audio(audio, rate=rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e87de43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('../datasets/voxceleb/vox2_meta.csv')\n",
    "meta.columns = [col.strip() for col in meta.columns]\n",
    "for col in meta:\n",
    "    meta[col] = meta[col].str.strip()\n",
    "\n",
    "id2gender = dict(zip(meta['VoxCeleb2 ID'], meta['Gender']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c417827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('../datasets/voxceleb/vox1_meta.csv', sep='\\t')\n",
    "meta.columns = [col.strip() for col in meta.columns]\n",
    "for col in meta:\n",
    "    meta[col] = meta[col].str.strip()\n",
    "\n",
    "id2gender = dict(zip(meta['VoxCeleb1 ID'], meta['Gender']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f02938e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker_files(root, speaker):\n",
    "    speaker_root = os.path.join(root, speaker)\n",
    "    files = glob(f'{speaker_root}/**/*.wav', recursive=True)\n",
    "    files = [file.removeprefix(f'{speaker_root}/') for file in files]\n",
    "    return files\n",
    "\n",
    "def get_file_duration_info(root, speaker, speaker_file):\n",
    "    filepath = os.path.join(root, speaker, speaker_file)\n",
    "    a, sr = sf.read(filepath)\n",
    "    n_frames = len(a)\n",
    "    duration = n_frames / sr\n",
    "    return filepath, n_frames, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7731a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814f526e1ee146a58a148c63169e8266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root = '/Users/alexnikko/prog/bss_coursework/datasets/voxceleb/voxceleb1/test/wav/'\n",
    "speakers = os.listdir(root)\n",
    "speakers.remove('.DS_Store')  # because it is macOS\n",
    "\n",
    "speakers_info = {}\n",
    "for speaker in tqdm(speakers):\n",
    "    speaker_info = {}\n",
    "    speaker_files = get_speaker_files(root, speaker)\n",
    "    speaker_duration = 0\n",
    "    for file in speaker_files:\n",
    "        filepath, n_frames, duration = get_file_duration_info(root, speaker, file)\n",
    "        speaker_info[file] = {\n",
    "            'n_frames': n_frames,\n",
    "            'duration': duration\n",
    "        }\n",
    "        speaker_duration += duration\n",
    "    speaker_info['total_duration'] = speaker_duration\n",
    "    speakers_info[speaker] = speaker_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "67efe89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672.2544104166666 hours\n"
     ]
    }
   ],
   "source": [
    "total_duration = 0\n",
    "for sp in speakers_info:\n",
    "    total_duration += speakers_info[sp]['total_duration']\n",
    "print(f'{total_duration / 60} hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be92adb8",
   "metadata": {},
   "source": [
    "This is enough for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf998d",
   "metadata": {},
   "source": [
    "for dataset I need following scheme:\n",
    "\n",
    "- male speakers: list of strings\n",
    "- female speakers: list of strings\n",
    "- speakers_info: mapping from speaker to his files\n",
    "- I need to filter this files by minimum duration (3 seconds e.g.)\n",
    "- I need to know how many frames in each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56667837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4874"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b8489718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3558"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filter(lambda x: x >= 5, durations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1228e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get root as input\n",
    "# return find speakers, split to male and female speakers, for each speaker find files and filter them\n",
    "\n",
    "def prepare_meta(root: str, id2gender: dict[str, str], minimum_duration: float):\n",
    "    speakers = os.listdir(root)\n",
    "    # because it is macOS\n",
    "    if '.DS_Store' in speakers:\n",
    "        speakers.remove('.DS_Store')\n",
    "    \n",
    "    \n",
    "    sp2files = defaultdict(list)\n",
    "    for speaker in speakers:\n",
    "        speaker_files = get_speaker_files(root, speaker)\n",
    "        for file in speaker_files:\n",
    "            _, n_frames, duration = get_file_duration_info(root, speaker, file)\n",
    "            if duration < minimum_duration:\n",
    "                continue\n",
    "            sp2files[speaker].append({\n",
    "                'rel_path': file,\n",
    "                'n_frames': n_frames\n",
    "            })\n",
    "    male_speakers = [speaker for speaker in speakers if id2gender[speaker] == 'm']\n",
    "    female_speakers = [speaker for speaker in speakers if id2gender[speaker] == 'f']\n",
    "    return male_speakers, female_speakers, sp2files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7fda2be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_speakers, female_speakers, sp2files = prepare_meta(root, id2gender, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae617b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 15)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(male_speakers), len(female_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "13eba337",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxcelebDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 root: str,\n",
    "                 male_speakers: list[str],\n",
    "                 female_speakers: list[str],\n",
    "                 sp2files: dict[str, list[dict[str, Union[str, int]]]],\n",
    "                 frames: int,\n",
    "                 steps: int,\n",
    "                 prob_same: float = 0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.root = root\n",
    "        self.male_speakers = male_speakers\n",
    "        self.female_speakers = female_speakers\n",
    "        self.sp2files = sp2files\n",
    "        self.steps = steps\n",
    "        self.prob_same = prob_same\n",
    "        assert 0 <= prob_same <= 1, f'prob_same must be in [0, 1], got {prob_same}'\n",
    "        self.list_of_choice_for_same = ['female', 'male']\n",
    "        self.prob_of_choice_for_same = [\n",
    "            len(female_speakers) / (len(female_speakers) + len(male_speakers)),\n",
    "            len(male_speakers) / (len(female_speakers) + len(male_speakers)),\n",
    "        ]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        if np.random.rand() < self.prob_same:\n",
    "            speakers = (self.female_speakers\n",
    "                        if np.random.choice(self.list_of_choice_for_same, p=self.prob_of_choice_for_same) == 'female'\n",
    "                        else self.male_speakers)\n",
    "            sp1, sp2 = np.random.choice(speakers, size=2, replace=False)\n",
    "        else:\n",
    "            sp1 = np.random.choise(self.male_speakers)\n",
    "            sp2 = np.random.choice(self.female_speakers)\n",
    "        \n",
    "        file1 = np.random.choice(self.sp2files[sp1])\n",
    "        file2 = np.random.choice(self.sp2files[sp2])\n",
    "        \n",
    "        rel_path1, rel_path2 = file1['rel_path'], file2['rel_path']\n",
    "        n_frames1, n_frames2 = file1['n_frames'], file2['n_frames']\n",
    "        \n",
    "        start1 = np.random.randint(n_frames1 - self.frames + 1)\n",
    "        start2 = np.random.randint(n_frames2 - self.frames + 1)\n",
    "        \n",
    "        path1, path2 = os.path.join(self.root, sp1, rel_path1), os.path.join(self.root, sp2, rel_path2)\n",
    "        \n",
    "        a1 = sf.read(path1, dtype='float32')[0]\n",
    "        a2 = sf.read(path2, dtype='float32')[0]\n",
    "        \n",
    "        mix = a1 + a2\n",
    "        \n",
    "        return mix, np.hstack([a1, a2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5209aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VoxcelebDataset(root, male_speakers, female_speakers, sp2files, frames=3 * SR, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4b10ee60",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2j/n69ns7lx5gl463gx31gt_m5r0000gn/T/ipykernel_84928/2411785438.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/2j/n69ns7lx5gl463gx31gt_m5r0000gn/T/ipykernel_84928/1925406629.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mn_frames1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_frames2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_frames'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_frames'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mstart1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_frames1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mstart2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_frames2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attribute_name)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98f65d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
